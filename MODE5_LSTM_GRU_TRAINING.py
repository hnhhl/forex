#!/usr/bin/env python3
"""
üîÆ MODE 5.1: LSTM/GRU MODELS TRAINING
Ultimate XAU Super System V4.0

Long Short-Term Memory v√† Gated Recurrent Unit Networks
cho Time Series Prediction n√¢ng cao
"""

import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, GRU, Dense, Dropout, BatchNormalization
from tensorflow.keras.optimizers import Adam
from sklearn.preprocessing import MinMaxScaler
import MetaTrader5 as mt5
from datetime import datetime
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class LSTMGRUTrainingSystem:
    """Advanced LSTM/GRU Training System"""
    
    def __init__(self):
        self.sequence_length = 60  # 60 bars lookback
        self.features = 67  # 67 technical indicators
        self.scaler = MinMaxScaler()
        
    def explain_lstm_gru(self):
        """Gi·∫£i th√≠ch LSTM/GRU"""
        print("üîÆ LSTM/GRU MODELS TRAINING")
        print("=" * 60)
        print("üìö KH√ÅI NI·ªÜM:")
        print("  ‚Ä¢ LSTM (Long Short-Term Memory):")
        print("    - Nh·ªõ th√¥ng tin d√†i h·∫°n trong time series")
        print("    - X·ª≠ l√Ω vanishing gradient problem")
        print("    - 3 gates: Forget, Input, Output")
        print("    - Ideal cho forex prediction")
        print()
        print("  ‚Ä¢ GRU (Gated Recurrent Unit):")
        print("    - Simplified version c·ªßa LSTM")
        print("    - 2 gates: Reset, Update")
        print("    - Faster training, √≠t parameters h∆°n")
        print("    - Good balance performance/speed")
        print()
        print("üéØ ·ª®NG D·ª§NG CHO XAU/USDc:")
        print("  ‚Ä¢ Sequence Learning: 60 bars ‚Üí 1 prediction")
        print("  ‚Ä¢ Pattern Recognition: Support/Resistance levels")
        print("  ‚Ä¢ Trend Continuation: Multi-step predictions")
        print("  ‚Ä¢ Market Memory: Remember past market conditions")
        print()
        
    def create_lstm_model(self, input_shape):
        """T·∫°o LSTM model architecture"""
        model = Sequential([
            # LSTM Layer 1
            LSTM(128, return_sequences=True, input_shape=input_shape),
            BatchNormalization(),
            Dropout(0.2),
            
            # LSTM Layer 2
            LSTM(64, return_sequences=True),
            BatchNormalization(),
            Dropout(0.2),
            
            # LSTM Layer 3
            LSTM(32, return_sequences=False),
            BatchNormalization(),
            Dropout(0.2),
            
            # Dense Layers
            Dense(16, activation='relu'),
            Dropout(0.1),
            Dense(3, activation='softmax')  # BUY/SELL/HOLD
        ])
        
        model.compile(
            optimizer=Adam(learning_rate=0.001),
            loss='categorical_crossentropy',
            metrics=['accuracy']
        )
        
        return model
        
    def create_gru_model(self, input_shape):
        """T·∫°o GRU model architecture"""
        model = Sequential([
            # GRU Layer 1
            GRU(128, return_sequences=True, input_shape=input_shape),
            BatchNormalization(),
            Dropout(0.2),
            
            # GRU Layer 2
            GRU(64, return_sequences=True),
            BatchNormalization(),
            Dropout(0.2),
            
            # GRU Layer 3
            GRU(32, return_sequences=False),
            BatchNormalization(),
            Dropout(0.2),
            
            # Dense Layers
            Dense(16, activation='relu'),
            Dropout(0.1),
            Dense(3, activation='softmax')  # BUY/SELL/HOLD
        ])
        
        model.compile(
            optimizer=Adam(learning_rate=0.001),
            loss='categorical_crossentropy',
            metrics=['accuracy']
        )
        
        return model
        
    def prepare_sequence_data(self, data):
        """Chu·∫©n b·ªã data cho sequence learning"""
        print("üìä Preparing sequence data...")
        
        # Create sequences
        X, y = [], []
        
        for i in range(self.sequence_length, len(data)):
            # 60 bars history ‚Üí 1 prediction
            X.append(data[i-self.sequence_length:i])
            y.append(data[i, -1])  # Target column
            
        X = np.array(X)
        y = np.array(y)
        
        print(f"  ‚úÖ Sequences created: {X.shape}")
        print(f"  ‚úÖ Input shape: (samples, timesteps, features)")
        print(f"  ‚úÖ X shape: {X.shape}")
        print(f"  ‚úÖ y shape: {y.shape}")
        
        return X, y
        
    def demo_training(self):
        """Demo LSTM/GRU training process"""
        print("üöÄ DEMO LSTM/GRU TRAINING")
        print("=" * 50)
        
        # Simulate data (in real system, load from MT5)
        samples = 1000
        sequence_length = self.sequence_length
        features = self.features
        
        # Create mock data
        X = np.random.random((samples, sequence_length, features))
        y = np.random.randint(0, 3, (samples, 3))  # One-hot encoded
        
        print(f"üìä Training Data:")
        print(f"  ‚Ä¢ Samples: {samples}")
        print(f"  ‚Ä¢ Sequence Length: {sequence_length} bars")
        print(f"  ‚Ä¢ Features: {features} indicators")
        print(f"  ‚Ä¢ Input Shape: {X.shape}")
        print()
        
        # Create models
        print("üîÆ Creating LSTM Model...")
        lstm_model = self.create_lstm_model((sequence_length, features))
        
        print("üîÑ Creating GRU Model...")
        gru_model = self.create_gru_model((sequence_length, features))
        
        # Model summaries
        print("\nüìã LSTM Model Architecture:")
        lstm_model.summary()
        
        print("\nüìã GRU Model Architecture:")
        gru_model.summary()
        
        # Training simulation
        print("\nüéØ Training Results (Simulated):")
        print("  LSTM Model:")
        print("    ‚Ä¢ Epoch 1/50: loss: 0.8234 - accuracy: 0.6543")
        print("    ‚Ä¢ Epoch 25/50: loss: 0.4567 - accuracy: 0.7834")
        print("    ‚Ä¢ Epoch 50/50: loss: 0.2341 - accuracy: 0.8756")
        print("    ‚Ä¢ Final Validation Accuracy: 87.56%")
        print()
        print("  GRU Model:")
        print("    ‚Ä¢ Epoch 1/50: loss: 0.7854 - accuracy: 0.6721")
        print("    ‚Ä¢ Epoch 25/50: loss: 0.4123 - accuracy: 0.8012")
        print("    ‚Ä¢ Epoch 50/50: loss: 0.2156 - accuracy: 0.8943")
        print("    ‚Ä¢ Final Validation Accuracy: 89.43%")
        print()
        
        return lstm_model, gru_model

if __name__ == "__main__":
    system = LSTMGRUTrainingSystem()
    system.explain_lstm_gru()
    system.demo_training() 