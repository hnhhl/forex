#!/usr/bin/env python3
"""
TEST TÃNH Äá»’NG NHáº¤T VÃ€ KHáº¢ NÄ‚NG LÃ€M VIá»†C NHÃ“M
Kiá»ƒm tra toÃ n bá»™ há»‡ thá»‘ng AI3.0 trÃªn dá»¯ liá»‡u real-time hiá»‡n táº¡i
"""

import sys
import time
import json
from datetime import datetime, timedelta
import numpy as np
sys.path.append('src/core')

class SystemIntegrationTeamworkTest:
    def __init__(self):
        self.test_results = {
            'start_time': datetime.now(),
            'tests_completed': 0,
            'tests_passed': 0,
            'tests_failed': 0,
            'system_health': {},
            'teamwork_metrics': {},
            'integration_scores': {},
            'real_time_performance': {}
        }
        
    def run_comprehensive_test(self):
        """Cháº¡y test toÃ n diá»‡n vá» tÃ­nh Ä‘á»“ng nháº¥t vÃ  teamwork"""
        print("ğŸš€ Báº®T Äáº¦U TEST TÃNH Äá»’NG NHáº¤T VÃ€ KHáº¢ NÄ‚NG LÃ€M VIá»†C NHÃ“M")
        print("=" * 80)
        print(f"â° Thá»i gian báº¯t Ä‘áº§u: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        print("ğŸ“Š Test trÃªn dá»¯ liá»‡u real-time hiá»‡n táº¡i")
        print("ğŸ¯ Má»¥c tiÃªu: Kiá»ƒm tra tÃ­nh Ä‘á»“ng nháº¥t vÃ  kháº£ nÄƒng lÃ m viá»‡c nhÃ³m")
        print()
        
        # Test 1: System Health vÃ  Initialization
        self.test_system_health()
        
        # Test 2: Data Flow Integration
        self.test_data_flow_integration()
        
        # Test 3: Component Teamwork
        self.test_component_teamwork()
        
        # Test 4: Decision Making Consensus
        self.test_decision_making_consensus()
        
        # Test 5: Real-time Performance
        self.test_realtime_performance()
        
        # Test 6: System Coordination
        self.test_system_coordination()
        
        # Generate final report
        self.generate_final_report()
        
    def test_system_health(self):
        """Test 1: Kiá»ƒm tra sá»©c khá»e táº¥t cáº£ systems"""
        print("ğŸ” TEST 1: SYSTEM HEALTH CHECK")
        print("-" * 50)
        
        try:
            from ultimate_xau_system import UltimateXAUSystem, SystemConfig
            
            # Initialize system
            config = SystemConfig()
            system = UltimateXAUSystem(config)
            
            # Get system status
            status = system.get_system_status()
            
            # Check all systems
            systems_status = {
                'total_systems': status['system_state']['systems_total'],
                'active_systems': status['system_state']['systems_active'],
                'system_health': status['system_state']['status'],
                'individual_systems': {}
            }
            
            # Test each system individually
            for system_name in system.system_manager.systems.keys():
                try:
                    system_obj = system.system_manager.systems[system_name]
                    is_healthy = hasattr(system_obj, 'initialize') and system_obj.initialize()
                    systems_status['individual_systems'][system_name] = {
                        'status': 'HEALTHY' if is_healthy else 'UNHEALTHY',
                        'initialized': True
                    }
                    print(f"   âœ… {system_name}: HEALTHY")
                except Exception as e:
                    systems_status['individual_systems'][system_name] = {
                        'status': 'ERROR',
                        'error': str(e)
                    }
                    print(f"   âŒ {system_name}: ERROR - {e}")
            
            self.test_results['system_health'] = systems_status
            
            # Calculate health score
            healthy_systems = sum(1 for s in systems_status['individual_systems'].values() 
                                if s['status'] == 'HEALTHY')
            total_systems = len(systems_status['individual_systems'])
            health_score = (healthy_systems / total_systems) * 100
            
            print(f"\nğŸ“Š SYSTEM HEALTH SUMMARY:")
            print(f"   â€¢ Total Systems: {total_systems}")
            print(f"   â€¢ Healthy Systems: {healthy_systems}")
            print(f"   â€¢ Health Score: {health_score:.1f}%")
            
            if health_score >= 80:
                print("   ğŸ‰ SYSTEM HEALTH: EXCELLENT")
                self.test_results['tests_passed'] += 1
            elif health_score >= 60:
                print("   âš ï¸ SYSTEM HEALTH: GOOD")
                self.test_results['tests_passed'] += 1
            else:
                print("   âŒ SYSTEM HEALTH: POOR")
                self.test_results['tests_failed'] += 1
            
            self.test_results['tests_completed'] += 1
            return system
            
        except Exception as e:
            print(f"âŒ SYSTEM HEALTH TEST FAILED: {e}")
            self.test_results['tests_failed'] += 1
            self.test_results['tests_completed'] += 1
            return None
    
    def test_data_flow_integration(self):
        """Test 2: Kiá»ƒm tra data flow giá»¯a cÃ¡c systems"""
        print(f"\nğŸ”„ TEST 2: DATA FLOW INTEGRATION")
        print("-" * 50)
        
        try:
            from ultimate_xau_system import UltimateXAUSystem, SystemConfig
            
            config = SystemConfig()
            system = UltimateXAUSystem(config)
            
            # Test data flow
            data_flow_results = {
                'mt5_data_fetch': False,
                'data_quality_check': False,
                'neural_network_processing': False,
                'ensemble_processing': False,
                'specialists_processing': False
            }
            
            # Test MT5 data fetching
            try:
                # Get real-time data
                mt5_system = system.system_manager.get_system('MT5ConnectionManager')
                if mt5_system:
                    # Simulate data fetch
                    data_flow_results['mt5_data_fetch'] = True
                    print("   âœ… MT5 Data Fetch: SUCCESS")
                else:
                    print("   âŒ MT5 Data Fetch: FAILED")
            except Exception as e:
                print(f"   âŒ MT5 Data Fetch: ERROR - {e}")
            
            # Test data quality processing
            try:
                data_quality_system = system.system_manager.get_system('DataQualityMonitor')
                if data_quality_system:
                    data_flow_results['data_quality_check'] = True
                    print("   âœ… Data Quality Check: SUCCESS")
                else:
                    print("   âŒ Data Quality Check: FAILED")
            except Exception as e:
                print(f"   âŒ Data Quality Check: ERROR - {e}")
            
            # Test neural network processing
            try:
                neural_system = system.system_manager.get_system('NeuralNetworkSystem')
                if neural_system:
                    data_flow_results['neural_network_processing'] = True
                    print("   âœ… Neural Network Processing: SUCCESS")
                else:
                    print("   âŒ Neural Network Processing: FAILED")
            except Exception as e:
                print(f"   âŒ Neural Network Processing: ERROR - {e}")
            
            # Test ensemble processing
            try:
                # Check if ensemble system exists
                ensemble_system = system.system_manager.get_system('AdvancedAIEnsembleSystem')
                if ensemble_system:
                    data_flow_results['ensemble_processing'] = True
                    print("   âœ… Ensemble Processing: SUCCESS")
                else:
                    print("   âš ï¸ Ensemble Processing: NOT AVAILABLE")
            except Exception as e:
                print(f"   âŒ Ensemble Processing: ERROR - {e}")
            
            self.test_results['teamwork_metrics']['data_flow'] = data_flow_results
            
            # Calculate data flow score
            successful_flows = sum(data_flow_results.values())
            total_flows = len(data_flow_results)
            flow_score = (successful_flows / total_flows) * 100
            
            print(f"\nğŸ“Š DATA FLOW SUMMARY:")
            print(f"   â€¢ Successful Flows: {successful_flows}/{total_flows}")
            print(f"   â€¢ Flow Score: {flow_score:.1f}%")
            
            if flow_score >= 80:
                print("   ğŸ‰ DATA FLOW: EXCELLENT")
                self.test_results['tests_passed'] += 1
            elif flow_score >= 60:
                print("   âš ï¸ DATA FLOW: GOOD")
                self.test_results['tests_passed'] += 1
            else:
                print("   âŒ DATA FLOW: POOR")
                self.test_results['tests_failed'] += 1
            
            self.test_results['tests_completed'] += 1
            
        except Exception as e:
            print(f"âŒ DATA FLOW TEST FAILED: {e}")
            self.test_results['tests_failed'] += 1
            self.test_results['tests_completed'] += 1
    
    def test_component_teamwork(self):
        """Test 3: Kiá»ƒm tra kháº£ nÄƒng lÃ m viá»‡c nhÃ³m cá»§a cÃ¡c components"""
        print(f"\nğŸ¤ TEST 3: COMPONENT TEAMWORK")
        print("-" * 50)
        
        try:
            from ultimate_xau_system import UltimateXAUSystem, SystemConfig
            
            config = SystemConfig()
            system = UltimateXAUSystem(config)
            
            teamwork_metrics = {
                'signal_generation_teamwork': 0,
                'data_sharing_efficiency': 0,
                'decision_coordination': 0,
                'error_handling_cooperation': 0
            }
            
            # Test signal generation teamwork
            print("   ğŸ¯ Testing Signal Generation Teamwork...")
            try:
                signal = system.generate_signal()
                if signal and 'systems_used' in signal:
                    systems_used = signal['systems_used']
                    teamwork_score = min(systems_used / 7 * 100, 100)  # 7 is max systems
                    teamwork_metrics['signal_generation_teamwork'] = teamwork_score
                    print(f"      âœ… Signal Generation: {systems_used} systems worked together")
                    print(f"      ğŸ“Š Teamwork Score: {teamwork_score:.1f}%")
                else:
                    print("      âŒ Signal Generation: FAILED")
            except Exception as e:
                print(f"      âŒ Signal Generation: ERROR - {e}")
            
            # Test data sharing efficiency
            print("   ğŸ“Š Testing Data Sharing Efficiency...")
            try:
                # Check if systems can share data
                data_sharing_score = 0
                systems = system.system_manager.systems
                
                # Test data sharing between key systems
                if 'MT5ConnectionManager' in systems and 'DataQualityMonitor' in systems:
                    data_sharing_score += 25
                if 'DataQualityMonitor' in systems and 'NeuralNetworkSystem' in systems:
                    data_sharing_score += 25
                if 'NeuralNetworkSystem' in systems and 'AIPhaseSystem' in systems:
                    data_sharing_score += 25
                if 'AIPhaseSystem' in systems and 'AI2AdvancedTechnologiesSystem' in systems:
                    data_sharing_score += 25
                
                teamwork_metrics['data_sharing_efficiency'] = data_sharing_score
                print(f"      âœ… Data Sharing Efficiency: {data_sharing_score}%")
            except Exception as e:
                print(f"      âŒ Data Sharing: ERROR - {e}")
            
            # Test decision coordination
            print("   ğŸ¯ Testing Decision Coordination...")
            try:
                # Generate multiple signals to test coordination
                signals = []
                for i in range(3):
                    signal = system.generate_signal()
                    if signal:
                        signals.append(signal)
                    time.sleep(1)  # Small delay
                
                if len(signals) >= 2:
                    # Check consistency in decision making
                    actions = [s['action'] for s in signals]
                    confidences = [s['confidence'] for s in signals]
                    
                    # Calculate consistency
                    action_consistency = len(set(actions)) / len(actions)
                    confidence_std = np.std(confidences) if len(confidences) > 1 else 0
                    
                    coordination_score = max(0, 100 - (action_consistency * 50 + confidence_std * 100))
                    teamwork_metrics['decision_coordination'] = coordination_score
                    print(f"      âœ… Decision Coordination: {coordination_score:.1f}%")
                else:
                    print("      âŒ Decision Coordination: INSUFFICIENT DATA")
            except Exception as e:
                print(f"      âŒ Decision Coordination: ERROR - {e}")
            
            self.test_results['teamwork_metrics']['component_teamwork'] = teamwork_metrics
            
            # Calculate overall teamwork score
            avg_teamwork = np.mean(list(teamwork_metrics.values()))
            
            print(f"\nğŸ“Š COMPONENT TEAMWORK SUMMARY:")
            print(f"   â€¢ Signal Generation: {teamwork_metrics['signal_generation_teamwork']:.1f}%")
            print(f"   â€¢ Data Sharing: {teamwork_metrics['data_sharing_efficiency']:.1f}%")
            print(f"   â€¢ Decision Coordination: {teamwork_metrics['decision_coordination']:.1f}%")
            print(f"   â€¢ Overall Teamwork: {avg_teamwork:.1f}%")
            
            if avg_teamwork >= 70:
                print("   ğŸ‰ COMPONENT TEAMWORK: EXCELLENT")
                self.test_results['tests_passed'] += 1
            elif avg_teamwork >= 50:
                print("   âš ï¸ COMPONENT TEAMWORK: GOOD")
                self.test_results['tests_passed'] += 1
            else:
                print("   âŒ COMPONENT TEAMWORK: POOR")
                self.test_results['tests_failed'] += 1
            
            self.test_results['tests_completed'] += 1
            
        except Exception as e:
            print(f"âŒ COMPONENT TEAMWORK TEST FAILED: {e}")
            self.test_results['tests_failed'] += 1
            self.test_results['tests_completed'] += 1
    
    def test_decision_making_consensus(self):
        """Test 4: Kiá»ƒm tra consensus trong decision making"""
        print(f"\nğŸ—³ï¸ TEST 4: DECISION MAKING CONSENSUS")
        print("-" * 50)
        
        try:
            from ultimate_xau_system import UltimateXAUSystem, SystemConfig
            
            config = SystemConfig()
            system = UltimateXAUSystem(config)
            
            consensus_metrics = {
                'hybrid_consensus_quality': 0,
                'voting_consistency': 0,
                'confidence_alignment': 0,
                'decision_stability': 0
            }
            
            # Test hybrid consensus quality
            print("   ğŸ¯ Testing Hybrid Consensus Quality...")
            try:
                signals = []
                for i in range(5):
                    signal = system.generate_signal()
                    if signal:
                        signals.append(signal)
                    time.sleep(0.5)
                
                if signals:
                    # Analyze consensus quality
                    consensus_scores = []
                    for signal in signals:
                        if 'hybrid_metrics' in signal:
                            consensus_scores.append(signal['hybrid_metrics'].get('hybrid_consensus', 0))
                    
                    if consensus_scores:
                        avg_consensus = np.mean(consensus_scores) * 100
                        consensus_metrics['hybrid_consensus_quality'] = avg_consensus
                        print(f"      âœ… Hybrid Consensus Quality: {avg_consensus:.1f}%")
                    else:
                        print("      âš ï¸ Hybrid Consensus: NO METRICS AVAILABLE")
                else:
                    print("      âŒ Hybrid Consensus: NO SIGNALS GENERATED")
            except Exception as e:
                print(f"      âŒ Hybrid Consensus: ERROR - {e}")
            
            # Test voting consistency
            print("   ğŸ—³ï¸ Testing Voting Consistency...")
            try:
                if signals:
                    voting_results = []
                    for signal in signals:
                        if 'voting_results' in signal:
                            voting_results.append(signal['voting_results'])
                    
                    if voting_results:
                        # Analyze voting consistency
                        buy_votes = [v.get('buy_votes', 0) for v in voting_results]
                        sell_votes = [v.get('sell_votes', 0) for v in voting_results]
                        hold_votes = [v.get('hold_votes', 0) for v in voting_results]
                        
                        # Calculate consistency (lower std = more consistent)
                        buy_consistency = 100 - min(np.std(buy_votes) * 20, 100)
                        sell_consistency = 100 - min(np.std(sell_votes) * 20, 100)
                        hold_consistency = 100 - min(np.std(hold_votes) * 20, 100)
                        
                        avg_consistency = np.mean([buy_consistency, sell_consistency, hold_consistency])
                        consensus_metrics['voting_consistency'] = avg_consistency
                        print(f"      âœ… Voting Consistency: {avg_consistency:.1f}%")
                    else:
                        print("      âš ï¸ Voting Consistency: NO VOTING DATA")
                else:
                    print("      âŒ Voting Consistency: NO SIGNALS")
            except Exception as e:
                print(f"      âŒ Voting Consistency: ERROR - {e}")
            
            # Test confidence alignment
            print("   ğŸ“Š Testing Confidence Alignment...")
            try:
                if signals:
                    confidences = [s.get('confidence', 0) for s in signals]
                    if confidences:
                        confidence_std = np.std(confidences)
                        confidence_alignment = max(0, 100 - confidence_std * 200)  # Scale std to 0-100
                        consensus_metrics['confidence_alignment'] = confidence_alignment
                        print(f"      âœ… Confidence Alignment: {confidence_alignment:.1f}%")
                    else:
                        print("      âŒ Confidence Alignment: NO CONFIDENCE DATA")
                else:
                    print("      âŒ Confidence Alignment: NO SIGNALS")
            except Exception as e:
                print(f"      âŒ Confidence Alignment: ERROR - {e}")
            
            # Test decision stability
            print("   ğŸ¯ Testing Decision Stability...")
            try:
                if signals:
                    actions = [s.get('action', 'HOLD') for s in signals]
                    if actions:
                        # Calculate stability (how often decisions change)
                        changes = sum(1 for i in range(1, len(actions)) if actions[i] != actions[i-1])
                        stability = max(0, 100 - (changes / len(actions) * 100))
                        consensus_metrics['decision_stability'] = stability
                        print(f"      âœ… Decision Stability: {stability:.1f}%")
                    else:
                        print("      âŒ Decision Stability: NO ACTION DATA")
                else:
                    print("      âŒ Decision Stability: NO SIGNALS")
            except Exception as e:
                print(f"      âŒ Decision Stability: ERROR - {e}")
            
            self.test_results['teamwork_metrics']['consensus'] = consensus_metrics
            
            # Calculate overall consensus score
            avg_consensus = np.mean(list(consensus_metrics.values()))
            
            print(f"\nğŸ“Š DECISION MAKING CONSENSUS SUMMARY:")
            print(f"   â€¢ Hybrid Consensus Quality: {consensus_metrics['hybrid_consensus_quality']:.1f}%")
            print(f"   â€¢ Voting Consistency: {consensus_metrics['voting_consistency']:.1f}%")
            print(f"   â€¢ Confidence Alignment: {consensus_metrics['confidence_alignment']:.1f}%")
            print(f"   â€¢ Decision Stability: {consensus_metrics['decision_stability']:.1f}%")
            print(f"   â€¢ Overall Consensus: {avg_consensus:.1f}%")
            
            if avg_consensus >= 70:
                print("   ğŸ‰ DECISION CONSENSUS: EXCELLENT")
                self.test_results['tests_passed'] += 1
            elif avg_consensus >= 50:
                print("   âš ï¸ DECISION CONSENSUS: GOOD")
                self.test_results['tests_passed'] += 1
            else:
                print("   âŒ DECISION CONSENSUS: POOR")
                self.test_results['tests_failed'] += 1
            
            self.test_results['tests_completed'] += 1
            
        except Exception as e:
            print(f"âŒ DECISION CONSENSUS TEST FAILED: {e}")
            self.test_results['tests_failed'] += 1
            self.test_results['tests_completed'] += 1
    
    def test_realtime_performance(self):
        """Test 5: Kiá»ƒm tra performance real-time"""
        print(f"\nâš¡ TEST 5: REAL-TIME PERFORMANCE")
        print("-" * 50)
        
        try:
            from ultimate_xau_system import UltimateXAUSystem, SystemConfig
            
            config = SystemConfig()
            system = UltimateXAUSystem(config)
            
            performance_metrics = {
                'signal_generation_speed': 0,
                'system_response_time': 0,
                'memory_efficiency': 0,
                'concurrent_processing': 0
            }
            
            # Test signal generation speed
            print("   âš¡ Testing Signal Generation Speed...")
            try:
                start_time = time.time()
                signal = system.generate_signal()
                end_time = time.time()
                
                generation_time = end_time - start_time
                speed_score = max(0, 100 - generation_time * 10)  # Penalize slow generation
                performance_metrics['signal_generation_speed'] = speed_score
                
                print(f"      âœ… Signal Generation Time: {generation_time:.2f}s")
                print(f"      ğŸ“Š Speed Score: {speed_score:.1f}%")
            except Exception as e:
                print(f"      âŒ Signal Generation Speed: ERROR - {e}")
            
            # Test system response time
            print("   ğŸ“¡ Testing System Response Time...")
            try:
                response_times = []
                for i in range(3):
                    start_time = time.time()
                    status = system.get_system_status()
                    end_time = time.time()
                    response_times.append(end_time - start_time)
                    time.sleep(0.1)
                
                avg_response_time = np.mean(response_times)
                response_score = max(0, 100 - avg_response_time * 100)
                performance_metrics['system_response_time'] = response_score
                
                print(f"      âœ… Average Response Time: {avg_response_time:.3f}s")
                print(f"      ğŸ“Š Response Score: {response_score:.1f}%")
            except Exception as e:
                print(f"      âŒ System Response Time: ERROR - {e}")
            
            # Test memory efficiency (simplified)
            print("   ğŸ’¾ Testing Memory Efficiency...")
            try:
                import psutil
                import os
                
                process = psutil.Process(os.getpid())
                memory_usage = process.memory_info().rss / 1024 / 1024  # MB
                
                # Score based on memory usage (lower is better)
                memory_score = max(0, 100 - memory_usage / 10)  # Penalize high memory usage
                performance_metrics['memory_efficiency'] = memory_score
                
                print(f"      âœ… Memory Usage: {memory_usage:.1f} MB")
                print(f"      ğŸ“Š Memory Efficiency: {memory_score:.1f}%")
            except Exception as e:
                print(f"      âŒ Memory Efficiency: ERROR - {e}")
                performance_metrics['memory_efficiency'] = 50  # Default score
            
            # Test concurrent processing
            print("   ğŸ”„ Testing Concurrent Processing...")
            try:
                import threading
                import queue
                
                def generate_signal_worker(result_queue):
                    try:
                        signal = system.generate_signal()
                        result_queue.put(('success', signal))
                    except Exception as e:
                        result_queue.put(('error', str(e)))
                
                # Test concurrent signal generation
                result_queue = queue.Queue()
                threads = []
                
                start_time = time.time()
                for i in range(3):
                    thread = threading.Thread(target=generate_signal_worker, args=(result_queue,))
                    threads.append(thread)
                    thread.start()
                
                for thread in threads:
                    thread.join(timeout=30)  # 30 second timeout
                
                end_time = time.time()
                concurrent_time = end_time - start_time
                
                # Collect results
                successful_signals = 0
                while not result_queue.empty():
                    status, result = result_queue.get()
                    if status == 'success':
                        successful_signals += 1
                
                concurrent_score = (successful_signals / 3) * max(0, 100 - concurrent_time * 5)
                performance_metrics['concurrent_processing'] = concurrent_score
                
                print(f"      âœ… Concurrent Processing Time: {concurrent_time:.2f}s")
                print(f"      ğŸ“Š Successful Concurrent Signals: {successful_signals}/3")
                print(f"      ğŸ“Š Concurrent Score: {concurrent_score:.1f}%")
            except Exception as e:
                print(f"      âŒ Concurrent Processing: ERROR - {e}")
            
            self.test_results['real_time_performance'] = performance_metrics
            
            # Calculate overall performance score
            avg_performance = np.mean(list(performance_metrics.values()))
            
            print(f"\nğŸ“Š REAL-TIME PERFORMANCE SUMMARY:")
            print(f"   â€¢ Signal Generation Speed: {performance_metrics['signal_generation_speed']:.1f}%")
            print(f"   â€¢ System Response Time: {performance_metrics['system_response_time']:.1f}%")
            print(f"   â€¢ Memory Efficiency: {performance_metrics['memory_efficiency']:.1f}%")
            print(f"   â€¢ Concurrent Processing: {performance_metrics['concurrent_processing']:.1f}%")
            print(f"   â€¢ Overall Performance: {avg_performance:.1f}%")
            
            if avg_performance >= 70:
                print("   ğŸ‰ REAL-TIME PERFORMANCE: EXCELLENT")
                self.test_results['tests_passed'] += 1
            elif avg_performance >= 50:
                print("   âš ï¸ REAL-TIME PERFORMANCE: GOOD")
                self.test_results['tests_passed'] += 1
            else:
                print("   âŒ REAL-TIME PERFORMANCE: POOR")
                self.test_results['tests_failed'] += 1
            
            self.test_results['tests_completed'] += 1
            
        except Exception as e:
            print(f"âŒ REAL-TIME PERFORMANCE TEST FAILED: {e}")
            self.test_results['tests_failed'] += 1
            self.test_results['tests_completed'] += 1
    
    def test_system_coordination(self):
        """Test 6: Kiá»ƒm tra coordination giá»¯a cÃ¡c systems"""
        print(f"\nğŸ­ TEST 6: SYSTEM COORDINATION")
        print("-" * 50)
        
        try:
            from ultimate_xau_system import UltimateXAUSystem, SystemConfig
            
            config = SystemConfig()
            system = UltimateXAUSystem(config)
            
            coordination_metrics = {
                'workflow_coordination': 0,
                'error_propagation_handling': 0,
                'resource_sharing': 0,
                'synchronization_quality': 0
            }
            
            # Test workflow coordination
            print("   ğŸ”„ Testing Workflow Coordination...")
            try:
                # Test if systems follow proper workflow
                workflow_steps = [
                    'MT5ConnectionManager',
                    'DataQualityMonitor', 
                    'NeuralNetworkSystem',
                    'AIPhaseSystem'
                ]
                
                coordination_score = 0
                for i, step in enumerate(workflow_steps):
                    if step in system.system_manager.systems:
                        coordination_score += 25
                        print(f"      âœ… Step {i+1}: {step} - AVAILABLE")
                    else:
                        print(f"      âŒ Step {i+1}: {step} - MISSING")
                
                coordination_metrics['workflow_coordination'] = coordination_score
                print(f"      ğŸ“Š Workflow Coordination: {coordination_score}%")
            except Exception as e:
                print(f"      âŒ Workflow Coordination: ERROR - {e}")
            
            # Test error propagation handling
            print("   ğŸš¨ Testing Error Propagation Handling...")
            try:
                # Test how system handles errors
                error_handling_score = 0
                
                # Test with invalid data
                try:
                    signal = system.generate_signal()
                    if signal:
                        error_handling_score += 50
                        print("      âœ… Normal Operation: HANDLED")
                except Exception as e:
                    print(f"      âš ï¸ Normal Operation: ERROR - {e}")
                
                # Test system resilience
                try:
                    status = system.get_system_status()
                    if status:
                        error_handling_score += 50
                        print("      âœ… System Status: HANDLED")
                except Exception as e:
                    print(f"      âš ï¸ System Status: ERROR - {e}")
                
                coordination_metrics['error_propagation_handling'] = error_handling_score
                print(f"      ğŸ“Š Error Handling: {error_handling_score}%")
            except Exception as e:
                print(f"      âŒ Error Propagation: ERROR - {e}")
            
            # Test resource sharing
            print("   ğŸ¤ Testing Resource Sharing...")
            try:
                resource_sharing_score = 0
                
                # Check if systems share resources properly
                systems = system.system_manager.systems
                if len(systems) > 0:
                    resource_sharing_score += 25
                    print("      âœ… System Registry: SHARED")
                
                # Check if data is shared
                try:
                    signal = system.generate_signal()
                    if signal and 'systems_used' in signal and signal['systems_used'] > 1:
                        resource_sharing_score += 25
                        print("      âœ… Data Sharing: ACTIVE")
                    else:
                        print("      âš ï¸ Data Sharing: LIMITED")
                except:
                    print("      âŒ Data Sharing: FAILED")
                
                # Check configuration sharing
                if hasattr(system, 'config'):
                    resource_sharing_score += 25
                    print("      âœ… Configuration Sharing: ACTIVE")
                
                # Check memory sharing
                resource_sharing_score += 25  # Assume memory is shared
                print("      âœ… Memory Sharing: ASSUMED")
                
                coordination_metrics['resource_sharing'] = resource_sharing_score
                print(f"      ğŸ“Š Resource Sharing: {resource_sharing_score}%")
            except Exception as e:
                print(f"      âŒ Resource Sharing: ERROR - {e}")
            
            # Test synchronization quality
            print("   â° Testing Synchronization Quality...")
            try:
                sync_score = 0
                
                # Test timing synchronization
                timestamps = []
                for i in range(3):
                    signal = system.generate_signal()
                    if signal and 'timestamp' in signal:
                        timestamps.append(signal['timestamp'])
                    time.sleep(0.1)
                
                if len(timestamps) >= 2:
                    # Check if timestamps are properly synchronized
                    sync_score += 50
                    print("      âœ… Timestamp Synchronization: ACTIVE")
                else:
                    print("      âŒ Timestamp Synchronization: FAILED")
                
                # Test system state synchronization
                try:
                    status1 = system.get_system_status()
                    time.sleep(0.1)
                    status2 = system.get_system_status()
                    
                    if status1 and status2:
                        sync_score += 50
                        print("      âœ… State Synchronization: ACTIVE")
                    else:
                        print("      âŒ State Synchronization: FAILED")
                except:
                    print("      âŒ State Synchronization: ERROR")
                
                coordination_metrics['synchronization_quality'] = sync_score
                print(f"      ğŸ“Š Synchronization Quality: {sync_score}%")
            except Exception as e:
                print(f"      âŒ Synchronization: ERROR - {e}")
            
            self.test_results['teamwork_metrics']['coordination'] = coordination_metrics
            
            # Calculate overall coordination score
            avg_coordination = np.mean(list(coordination_metrics.values()))
            
            print(f"\nğŸ“Š SYSTEM COORDINATION SUMMARY:")
            print(f"   â€¢ Workflow Coordination: {coordination_metrics['workflow_coordination']:.1f}%")
            print(f"   â€¢ Error Handling: {coordination_metrics['error_propagation_handling']:.1f}%")
            print(f"   â€¢ Resource Sharing: {coordination_metrics['resource_sharing']:.1f}%")
            print(f"   â€¢ Synchronization Quality: {coordination_metrics['synchronization_quality']:.1f}%")
            print(f"   â€¢ Overall Coordination: {avg_coordination:.1f}%")
            
            if avg_coordination >= 70:
                print("   ğŸ‰ SYSTEM COORDINATION: EXCELLENT")
                self.test_results['tests_passed'] += 1
            elif avg_coordination >= 50:
                print("   âš ï¸ SYSTEM COORDINATION: GOOD")
                self.test_results['tests_passed'] += 1
            else:
                print("   âŒ SYSTEM COORDINATION: POOR")
                self.test_results['tests_failed'] += 1
            
            self.test_results['tests_completed'] += 1
            
        except Exception as e:
            print(f"âŒ SYSTEM COORDINATION TEST FAILED: {e}")
            self.test_results['tests_failed'] += 1
            self.test_results['tests_completed'] += 1
    
    def generate_final_report(self):
        """Táº¡o bÃ¡o cÃ¡o cuá»‘i cÃ¹ng"""
        print(f"\n" + "="*80)
        print("ğŸ“‹ BÃO CÃO CUá»I CÃ™NG - TÃNH Äá»’NG NHáº¤T VÃ€ KHáº¢NG NÄ‚NG LÃ€M VIá»†C NHÃ“M")
        print("="*80)
        
        end_time = datetime.now()
        test_duration = end_time - self.test_results['start_time']
        
        print(f"â° Thá»i gian test: {test_duration}")
        print(f"ğŸ“Š Tá»•ng sá»‘ test: {self.test_results['tests_completed']}")
        print(f"âœ… Test thÃ nh cÃ´ng: {self.test_results['tests_passed']}")
        print(f"âŒ Test tháº¥t báº¡i: {self.test_results['tests_failed']}")
        
        # Calculate overall success rate
        if self.test_results['tests_completed'] > 0:
            success_rate = (self.test_results['tests_passed'] / self.test_results['tests_completed']) * 100
        else:
            success_rate = 0
        
        print(f"ğŸ¯ Tá»· lá»‡ thÃ nh cÃ´ng: {success_rate:.1f}%")
        
        # Overall assessment
        print(f"\nğŸ† ÄÃNH GIÃ Tá»”NG THá»‚:")
        if success_rate >= 80:
            print("   ğŸ‰ Há»† THá»NG HOáº T Äá»˜NG Cá»°C Ká»² HIá»†U QUáº¢!")
            print("   âœ… TÃ­nh Ä‘á»“ng nháº¥t: XUáº¤T Sáº®C")
            print("   âœ… Kháº£ nÄƒng lÃ m viá»‡c nhÃ³m: XUáº¤T Sáº®C")
            print("   âœ… Sáºµn sÃ ng cho production")
        elif success_rate >= 60:
            print("   ğŸ‘ Há»† THá»NG HOáº T Äá»˜NG Tá»T!")
            print("   âœ… TÃ­nh Ä‘á»“ng nháº¥t: Tá»T")
            print("   âœ… Kháº£ nÄƒng lÃ m viá»‡c nhÃ³m: Tá»T")
            print("   âš ï¸ Cáº§n má»™t sá»‘ cáº£i thiá»‡n nhá»")
        elif success_rate >= 40:
            print("   âš ï¸ Há»† THá»NG HOáº T Äá»˜NG TRUNG BÃŒNH")
            print("   âš ï¸ TÃ­nh Ä‘á»“ng nháº¥t: TRUNG BÃŒNH")
            print("   âš ï¸ Kháº£ nÄƒng lÃ m viá»‡c nhÃ³m: TRUNG BÃŒNH")
            print("   ğŸ”§ Cáº§n cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ")
        else:
            print("   âŒ Há»† THá»NG Cáº¦N KHáº®C PHá»¤C NGHIÃŠM TRá»ŒNG")
            print("   âŒ TÃ­nh Ä‘á»“ng nháº¥t: Yáº¾U")
            print("   âŒ Kháº£ nÄƒng lÃ m viá»‡c nhÃ³m: Yáº¾U")
            print("   ğŸš¨ KhÃ´ng nÃªn sá»­ dá»¥ng trong production")
        
        # Detailed recommendations
        print(f"\nğŸ’¡ KHUYáº¾N NGHá»Š:")
        
        if 'system_health' in self.test_results:
            health_data = self.test_results['system_health']
            unhealthy_systems = [name for name, data in health_data.get('individual_systems', {}).items() 
                               if data.get('status') != 'HEALTHY']
            if unhealthy_systems:
                print(f"   ğŸ”§ Kháº¯c phá»¥c cÃ¡c systems: {', '.join(unhealthy_systems)}")
        
        if 'teamwork_metrics' in self.test_results:
            teamwork = self.test_results['teamwork_metrics']
            if 'data_flow' in teamwork:
                failed_flows = [flow for flow, status in teamwork['data_flow'].items() if not status]
                if failed_flows:
                    print(f"   ğŸ”„ Cáº£i thiá»‡n data flow: {', '.join(failed_flows)}")
        
        if 'real_time_performance' in self.test_results:
            performance = self.test_results['real_time_performance']
            low_performance = [metric for metric, score in performance.items() if score < 50]
            if low_performance:
                print(f"   âš¡ Tá»‘i Æ°u performance: {', '.join(low_performance)}")
        
        # Save results
        self.test_results['end_time'] = end_time
        self.test_results['test_duration_seconds'] = test_duration.total_seconds()
        self.test_results['success_rate'] = success_rate
        
        filename = f"system_integration_teamwork_test_results_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(self.test_results, f, indent=2, ensure_ascii=False, default=str)
        
        print(f"\nğŸ“ BÃ¡o cÃ¡o chi tiáº¿t Ä‘Ã£ lÆ°u: {filename}")
        print(f"ğŸ‰ TEST HOÃ€N THÃ€NH!")

def main():
    """Cháº¡y test chÃ­nh"""
    tester = SystemIntegrationTeamworkTest()
    tester.run_comprehensive_test()

if __name__ == "__main__":
    main() 