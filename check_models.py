import os
import json
from datetime import datetime

def check_training_system():
    """Ki·ªÉm tra h·ªá th·ªëng training hi·ªán t·∫°i"""
    
    print("üîç KI·ªÇM TRA H·ªÜ TH·ªêNG TRAINING AI3.0")
    print("=" * 50)
    
    # Ki·ªÉm tra trained_models
    models_dir = "trained_models"
    if os.path.exists(models_dir):
        files = os.listdir(models_dir)
        total_files = len(files)
        
        # Ph√¢n lo·∫°i theo extension
        pkl_files = [f for f in files if f.endswith('.pkl')]
        keras_files = [f for f in files if f.endswith('.keras')]
        h5_files = [f for f in files if f.endswith('.h5')]
        json_files = [f for f in files if f.endswith('.json')]
        
        print(f"üìÅ TRAINED MODELS DIRECTORY:")
        print(f"   ‚Ä¢ Total files: {total_files}")
        print(f"   ‚Ä¢ PKL files (Traditional ML): {len(pkl_files)}")
        print(f"   ‚Ä¢ Keras files (Neural Networks): {len(keras_files)}")
        print(f"   ‚Ä¢ H5 files (Legacy Neural): {len(h5_files)}")
        print(f"   ‚Ä¢ JSON files (Config): {len(json_files)}")
        print(f"   ‚Ä¢ Total Models: {len(pkl_files) + len(keras_files) + len(h5_files)}")
        
        # Ki·ªÉm tra unified models
        unified_dir = os.path.join(models_dir, "unified")
        if os.path.exists(unified_dir):
            unified_files = os.listdir(unified_dir)
            unified_models = [f for f in unified_files if f.endswith(('.pkl', '.keras', '.h5'))]
            print(f"   ‚Ä¢ Unified Models: {len(unified_models)}")
        
    else:
        print("‚ùå trained_models directory not found!")
    
    print()
    
    # Ki·ªÉm tra training results
    results_dirs = [
        "training_results",
        "smart_training_results", 
        "training_reports",
        "optimized_training_results",
        "real_training_results"
    ]
    
    print(f"üìä TRAINING RESULTS:")
    total_results = 0
    for results_dir in results_dirs:
        if os.path.exists(results_dir):
            files = os.listdir(results_dir)
            result_files = [f for f in files if f.endswith('.json')]
            total_results += len(result_files)
            print(f"   ‚Ä¢ {results_dir}: {len(result_files)} results")
    
    print(f"   ‚Ä¢ Total Results: {total_results}")
    print()
    
    # Ki·ªÉm tra training systems
    print(f"üöÄ TRAINING SYSTEMS:")
    training_systems = [
        "MASS_TRAINING_SYSTEM_AI30.py",
        "comprehensive_training_fixed.py", 
        "demo_mass_training.py",
        "mass_training_demo.py"
    ]
    
    available_systems = []
    for system in training_systems:
        if os.path.exists(system):
            available_systems.append(system)
            size = os.path.getsize(system) / 1024  # KB
            print(f"   ‚úÖ {system} ({size:.1f} KB)")
        else:
            print(f"   ‚ùå {system} (not found)")
    
    print(f"   ‚Ä¢ Available Systems: {len(available_systems)}")
    print()
    
    # Ki·ªÉm tra data directories
    print(f"üíæ DATA DIRECTORIES:")
    data_dirs = [
        "data",
        "learning_data",
        "training/xauusdc"
    ]
    
    for data_dir in data_dirs:
        if os.path.exists(data_dir):
            try:
                files = os.listdir(data_dir)
                csv_files = [f for f in files if f.endswith('.csv')]
                pkl_files = [f for f in files if f.endswith('.pkl')]
                print(f"   ‚úÖ {data_dir}: {len(files)} files ({len(csv_files)} CSV, {len(pkl_files)} PKL)")
            except:
                print(f"   ‚ö†Ô∏è {data_dir}: Access denied")
        else:
            print(f"   ‚ùå {data_dir}: Not found")
    
    print()
    
    # Summary
    print(f"üéØ SUMMARY:")
    print(f"   ‚Ä¢ Total Models Available: {len(pkl_files) + len(keras_files) + len(h5_files) if 'pkl_files' in locals() else 'Unknown'}")
    print(f"   ‚Ä¢ Training Systems: {len(available_systems)}")
    print(f"   ‚Ä¢ Training Results: {total_results}")
    print(f"   ‚Ä¢ System Status: {'Ready for Training' if available_systems else 'Setup Required'}")
    
    return {
        'total_models': len(pkl_files) + len(keras_files) + len(h5_files) if 'pkl_files' in locals() else 0,
        'training_systems': len(available_systems),
        'training_results': total_results,
        'status': 'ready' if available_systems else 'setup_required'
    }

if __name__ == "__main__":
    result = check_training_system()
    
    # Save results
    with open(f'training_system_check_{datetime.now().strftime("%Y%m%d_%H%M%S")}.json', 'w') as f:
        json.dump(result, f, indent=2) 