import pandas as pd
import numpy as np
import pickle
import tensorflow as tf
from sklearn.metrics import accuracy_score, f1_score
import json
import os
from datetime import datetime

print("ğŸ¯ KIá»‚M TRA THá»°C Táº¾ CHáº¤T LÆ¯á»¢NG MODELS")
print("="*50)

# Load sample data from one timeframe to test
print("\nğŸ“Š Loading test data...")
try:
    # Load M15 data as sample
    with open('training/xauusdc/data/M15_data.pkl', 'rb') as f:
        m15_data = pickle.load(f)
    
    print(f"âœ… Loaded M15 data: {len(m15_data)} samples")
    
    # Prepare test data (last 500 samples)
    test_size = min(500, len(m15_data))
    test_data = m15_data.tail(test_size).copy()
    
    # Get features (exclude target columns)
    feature_cols = [col for col in test_data.columns if not col.startswith('y_direction') and col != 'timestamp']
    X_test = test_data[feature_cols].values
    
    # Get targets
    targets = {}
    for target_col in ['y_direction_2', 'y_direction_4', 'y_direction_8']:
        if target_col in test_data.columns:
            targets[target_col] = test_data[target_col].values
    
    print(f"ğŸ“ˆ Test samples: {test_size}")
    print(f"ğŸ“Š Features: {len(feature_cols)}")
    print(f"ğŸ¯ Targets: {list(targets.keys())}")
    
except Exception as e:
    print(f"âŒ Error loading data: {e}")
    exit()

# Test results
results = {
    'test_time': datetime.now().isoformat(),
    'test_samples': test_size,
    'models_tested': {},
    'summary': {}
}

print("\nğŸ§  TESTING NEURAL MODELS")
print("-" * 30)

neural_accuracies = []

for target in targets.keys():
    print(f"\nğŸ“Š Testing {target}...")
    
    try:
        # Load scaler
        scaler_path = f'trained_models/scaler_{target}.pkl'
        if not os.path.exists(scaler_path):
            print(f"  âŒ Scaler not found: {scaler_path}")
            continue
            
        with open(scaler_path, 'rb') as f:
            scaler = pickle.load(f)
        
        X_test_scaled = scaler.transform(X_test)
        
        # Test LSTM model
        lstm_path = f'trained_models/neural_ensemble_{target}_lstm.h5'
        if os.path.exists(lstm_path):
            lstm_model = tf.keras.models.load_model(lstm_path)
            
            # Prepare LSTM input
            X_test_lstm = X_test_scaled.reshape((X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))
            lstm_pred = lstm_model.predict(X_test_lstm, verbose=0)
            lstm_pred_binary = (lstm_pred > 0.5).astype(int).flatten()
            
            lstm_acc = accuracy_score(targets[target], lstm_pred_binary)
            lstm_f1 = f1_score(targets[target], lstm_pred_binary)
            
            print(f"  ğŸ”¸ LSTM: Accuracy={lstm_acc:.4f} ({lstm_acc*100:.1f}%) | F1={lstm_f1:.4f}")
            neural_accuracies.append(lstm_acc)
        
        # Test Dense model
        dense_path = f'trained_models/neural_ensemble_{target}_dense.h5'
        if os.path.exists(dense_path):
            dense_model = tf.keras.models.load_model(dense_path)
            
            dense_pred = dense_model.predict(X_test_scaled, verbose=0)
            dense_pred_binary = (dense_pred > 0.5).astype(int).flatten()
            
            dense_acc = accuracy_score(targets[target], dense_pred_binary)
            dense_f1 = f1_score(targets[target], dense_pred_binary)
            
            print(f"  ğŸ”¸ Dense: Accuracy={dense_acc:.4f} ({dense_acc*100:.1f}%) | F1={dense_f1:.4f}")
            neural_accuracies.append(dense_acc)
        
        results['models_tested'][f'neural_{target}'] = {
            'lstm_accuracy': float(lstm_acc) if 'lstm_acc' in locals() else 0,
            'dense_accuracy': float(dense_acc) if 'dense_acc' in locals() else 0
        }
        
    except Exception as e:
        print(f"  âŒ Error testing {target}: {e}")

print("\nğŸŒ² TESTING TRADITIONAL MODELS")
print("-" * 30)

traditional_accuracies = []

for target in targets.keys():
    print(f"\nğŸ“Š Testing {target}...")
    
    try:
        # Load scaler
        scaler_path = f'trained_models/scaler_{target}.pkl'
        if not os.path.exists(scaler_path):
            continue
            
        with open(scaler_path, 'rb') as f:
            scaler = pickle.load(f)
        
        X_test_scaled = scaler.transform(X_test)
        
        models = ['random_forest', 'gradient_boost', 'lightgbm']
        
        for model_name in models:
            model_path = f'trained_models/{model_name}_{target}.pkl'
            
            if os.path.exists(model_path):
                with open(model_path, 'rb') as f:
                    model = pickle.load(f)
                
                pred = model.predict(X_test_scaled)
                acc = accuracy_score(targets[target], pred)
                f1 = f1_score(targets[target], pred)
                
                print(f"  ğŸ”¸ {model_name}: Accuracy={acc:.4f} ({acc*100:.1f}%) | F1={f1:.4f}")
                traditional_accuracies.append(acc)
        
    except Exception as e:
        print(f"  âŒ Error testing traditional models for {target}: {e}")

# Calculate summary
print("\nğŸ“Š Tá»”NG Káº¾T THá»°C Táº¾")
print("=" * 50)

all_accuracies = neural_accuracies + traditional_accuracies

if all_accuracies:
    avg_acc = np.mean(all_accuracies)
    max_acc = np.max(all_accuracies)
    min_acc = np.min(all_accuracies)
    
    print(f"ğŸ¯ Äá»™ chÃ­nh xÃ¡c trung bÃ¬nh: {avg_acc:.4f} ({avg_acc*100:.1f}%)")
    print(f"ğŸ† Äá»™ chÃ­nh xÃ¡c cao nháº¥t: {max_acc:.4f} ({max_acc*100:.1f}%)")
    print(f"ğŸ“‰ Äá»™ chÃ­nh xÃ¡c tháº¥p nháº¥t: {min_acc:.4f} ({min_acc*100:.1f}%)")
    print(f"ğŸ“Š Tá»•ng sá»‘ models test: {len(all_accuracies)}")
    
    # Performance assessment
    print("\nğŸ ÄÃNH GIÃ Má»¨C Äá»˜ THÃ€NH CÃ”NG:")
    if avg_acc >= 0.70:
        success_level = "XUáº¤T Sáº®C"
        status = "âœ…"
    elif avg_acc >= 0.60:
        success_level = "KHÃ Tá»T"
        status = "âš ï¸"
    elif avg_acc >= 0.55:
        success_level = "TRUNG BÃŒNH"
        status = "ğŸ”¶"
    else:
        success_level = "Cáº¦N Cáº¢I THIá»†N"
        status = "âŒ"
    
    print(f"{status} Má»©c Ä‘á»™: {success_level}")
    print(f"ğŸ“ˆ Tá»· lá»‡ thÃ nh cÃ´ng: {avg_acc*100:.1f}%")
    
    # Specific analysis
    if len(neural_accuracies) > 0:
        neural_avg = np.mean(neural_accuracies)
        print(f"ğŸ§  Neural Models trung bÃ¬nh: {neural_avg:.4f} ({neural_avg*100:.1f}%)")
    
    if len(traditional_accuracies) > 0:
        trad_avg = np.mean(traditional_accuracies)
        print(f"ğŸŒ² Traditional Models trung bÃ¬nh: {trad_avg:.4f} ({trad_avg*100:.1f}%)")
    
    results['summary'] = {
        'average_accuracy': float(avg_acc),
        'max_accuracy': float(max_acc),
        'min_accuracy': float(min_acc),
        'success_level': success_level,
        'neural_models_count': len(neural_accuracies),
        'traditional_models_count': len(traditional_accuracies)
    }
    
    # Save results
    results_file = f'quick_model_test_results_{datetime.now().strftime("%Y%m%d_%H%M%S")}.json'
    with open(results_file, 'w') as f:
        json.dump(results, f, indent=2)
    
    print(f"\nğŸ’¾ Káº¿t quáº£ chi tiáº¿t Ä‘Ã£ lÆ°u: {results_file}")
    
else:
    print("âŒ KHÃ”NG THá»‚ TEST MODEL NÃ€O - CÃ³ váº¥n Ä‘á» nghiÃªm trá»ng!")

print("\n" + "="*50)
print("ğŸ¯ Káº¾T LUáº¬N: THÃ€NH CÃ”NG LÃ€...")
if all_accuracies and avg_acc >= 0.55:
    print("âœ… CÃ“ THÃ€NH CÃ”NG - Models hoáº¡t Ä‘á»™ng vÃ  cho káº¿t quáº£ kháº£ quan")
    print(f"ğŸ“Š {len(all_accuracies)} models hoáº¡t Ä‘á»™ng vá»›i Ä‘á»™ chÃ­nh xÃ¡c {avg_acc*100:.1f}%")
else:
    print("âŒ CHÆ¯A THÃ€NH CÃ”NG HOÃ€N TOÃ€N - Cáº§n cáº£i thiá»‡n thÃªm")
print("="*50) 