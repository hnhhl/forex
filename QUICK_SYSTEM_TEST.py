import pandas as pd
import numpy as np
import os
from datetime import datetime

print("ğŸ§ª QUICK SYSTEM TEST - ULTIMATE SYSTEM V5.0")
print("="*50)
print("ğŸ” Kiá»ƒm tra nguyÃªn nhÃ¢n process bá»‹ treo...")

# Test 1: Import libraries
print("\n1ï¸âƒ£ TESTING IMPORTS:")
try:
    import tensorflow as tf
    print("  âœ… TensorFlow:", tf.__version__)
except Exception as e:
    print(f"  âŒ TensorFlow error: {e}")

try:
    import sklearn
    print("  âœ… Scikit-learn:", sklearn.__version__)
except Exception as e:
    print(f"  âŒ Scikit-learn error: {e}")

try:
    import lightgbm as lgb
    print("  âœ… LightGBM:", lgb.__version__)
except Exception as e:
    print(f"  âŒ LightGBM error: {e}")

try:
    import xgboost as xgb
    print("  âœ… XGBoost:", xgb.__version__)
except Exception as e:
    print(f"  âŒ XGBoost error: {e}")

# Test 2: Data loading
print("\n2ï¸âƒ£ TESTING DATA LOADING:")
data_files = [
    'training/xauusdc/data/M15_data.pkl',
    'training/xauusdc/data/M30_data.pkl',
    'training/xauusdc/data/H1_data.pkl'
]

data_found = False
for file_path in data_files:
    if os.path.exists(file_path):
        try:
            import pickle
            with open(file_path, 'rb') as f:
                data = pickle.load(f)
            
            if isinstance(data, dict):
                df = pd.DataFrame(data)
            else:
                df = data
                
            print(f"  âœ… Loaded {file_path}: {len(df)} rows, {len(df.columns)} cols")
            data_found = True
            break
        except Exception as e:
            print(f"  âŒ Error loading {file_path}: {e}")

if not data_found:
    print("  âš ï¸ No data files found - using synthetic data")

# Test 3: Simple model creation
print("\n3ï¸âƒ£ TESTING MODEL CREATION:")
try:
    from tensorflow.keras.models import Sequential
    from tensorflow.keras.layers import Dense
    
    model = Sequential([
        Dense(10, input_dim=5, activation='relu'),
        Dense(1, activation='sigmoid')
    ])
    model.compile(optimizer='adam', loss='binary_crossentropy')
    print("  âœ… Simple neural network created successfully")
except Exception as e:
    print(f"  âŒ Neural network error: {e}")

# Test 4: Memory usage
print("\n4ï¸âƒ£ TESTING MEMORY:")
try:
    import psutil
    memory = psutil.virtual_memory()
    print(f"  ğŸ’¾ Available RAM: {memory.available/1024**3:.1f}GB")
    print(f"  ğŸ’¾ Used RAM: {memory.percent:.1f}%")
    
    if memory.percent > 80:
        print("  âš ï¸ High memory usage - may cause issues")
    else:
        print("  âœ… Memory usage normal")
except Exception as e:
    print(f"  âŒ Memory check error: {e}")

# Test 5: Synthetic training test
print("\n5ï¸âƒ£ QUICK TRAINING TEST:")
try:
    # Create small synthetic dataset
    np.random.seed(42)
    X = np.random.randn(100, 10)
    y = np.random.randint(0, 2, 100)
    
    from sklearn.ensemble import RandomForestClassifier
    rf = RandomForestClassifier(n_estimators=10)
    rf.fit(X, y)
    accuracy = rf.score(X, y)
    
    print(f"  âœ… Quick RF training: {accuracy:.3f} accuracy")
    
    # Test neural network
    from tensorflow.keras.models import Sequential
    from tensorflow.keras.layers import Dense
    
    nn = Sequential([
        Dense(5, input_dim=10, activation='relu'),
        Dense(1, activation='sigmoid')
    ])
    nn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
    history = nn.fit(X, y, epochs=5, verbose=0)
    
    print(f"  âœ… Quick NN training: {history.history['accuracy'][-1]:.3f} accuracy")
    
except Exception as e:
    print(f"  âŒ Training test error: {e}")

# Test 6: File system
print("\n6ï¸âƒ£ TESTING FILE SYSTEM:")
try:
    test_file = f"test_file_{datetime.now().strftime('%H%M%S')}.tmp"
    with open(test_file, 'w') as f:
        f.write("test data")
    
    # Read back
    with open(test_file, 'r') as f:
        content = f.read()
    
    os.remove(test_file)
    print("  âœ… File I/O working normally")
    
except Exception as e:
    print(f"  âŒ File I/O error: {e}")

print(f"\n{'='*50}")
print("ğŸ¯ DIAGNOSIS SUMMARY:")

# Possible issues analysis
issues = []
if not data_found:
    issues.append("âŒ Data loading issues")

print("ğŸ“‹ POSSIBLE CAUSES OF HANGING:")
print("  1. ğŸ”„ Infinite loop in training process")
print("  2. ğŸ’¾ Memory leak causing slowdown") 
print("  3. ğŸ§  Neural network training stuck")
print("  4. ğŸ“Š Cross-validation taking too long")
print("  5. ğŸ”¢ Large dataset causing timeout")

print("\nğŸ’¡ RECOMMENDED SOLUTIONS:")
print("  1. ğŸš€ Run simplified version with smaller data")
print("  2. âš¡ Reduce epochs/iterations")
print("  3. ğŸ¯ Skip complex components first")
print("  4. ğŸ“Š Add progress monitoring")

print(f"\nâ° Test completed at: {datetime.now().strftime('%H:%M:%S')}")
print(f"{'='*50}") 