import pickle
import pandas as pd
import numpy as np
from datetime import datetime
import os

print("ğŸ” PHÃ‚N TÃCH TOÃ€N Bá»˜ Dá»® LIá»†U MULTI-TIMEFRAME")
print("="*60)

# Danh sÃ¡ch cÃ¡c timeframes
timeframes = ['M1', 'M5', 'M15', 'M30', 'H1', 'H4', 'D1']
data_summary = {}

print("ğŸ“Š BÆ¯á»šC 1: PHÃ‚N TÃCH Cáº¤U TRÃšC Dá»® LIá»†U")
print("-"*40)

for tf in timeframes:
    print(f"\nğŸ”¸ Analyzing {tf} data...")
    
    try:
        # Load data
        data_file = f'training/xauusdc/data/{tf}_data.pkl'
        with open(data_file, 'rb') as f:
            data = pickle.load(f)
        
        # Analyze structure
        summary = {
            'file_size_mb': os.path.getsize(data_file) / (1024*1024),
            'data_type': type(data).__name__,
            'keys': list(data.keys()) if isinstance(data, dict) else 'Not a dict',
            'samples': len(data['X']) if isinstance(data, dict) and 'X' in data else 'Unknown',
            'features': data['X'].shape[1] if isinstance(data, dict) and 'X' in data else 'Unknown',
            'feature_names': data['feature_names'][:5] if isinstance(data, dict) and 'feature_names' in data else 'Unknown',
            'timestamp_range': None,
            'targets_available': []
        }
        
        # Analyze timestamps
        if isinstance(data, dict) and 'timestamps' in data:
            timestamps = data['timestamps']
            if len(timestamps) > 0:
                # Convert to datetime if needed
                if isinstance(timestamps[0], (int, float)):
                    start_time = pd.to_datetime(timestamps[0], unit='s')
                    end_time = pd.to_datetime(timestamps[-1], unit='s')
                else:
                    start_time = timestamps[0]
                    end_time = timestamps[-1]
                
                summary['timestamp_range'] = {
                    'start': str(start_time),
                    'end': str(end_time),
                    'duration_days': (pd.to_datetime(end_time) - pd.to_datetime(start_time)).days
                }
        
        # Analyze targets
        if isinstance(data, dict):
            for key in data.keys():
                if key.startswith('y_'):
                    target_info = {
                        'name': key,
                        'shape': data[key].shape,
                        'positive_rate': np.mean(data[key]) if data[key].dtype in [bool, int] else 'N/A'
                    }
                    summary['targets_available'].append(target_info)
        
        data_summary[tf] = summary
        
        print(f"   âœ… {tf}: {summary['samples']} samples, {summary['features']} features")
        print(f"      ğŸ“ Size: {summary['file_size_mb']:.1f}MB")
        print(f"      ğŸ¯ Targets: {len(summary['targets_available'])}")
        
    except Exception as e:
        print(f"   âŒ Error loading {tf}: {e}")
        data_summary[tf] = {'error': str(e)}

print(f"\nğŸ“‹ BÆ¯á»šC 2: Tá»”NG Há»¢P THÃ”NG TIN")
print("-"*40)

# Calculate totals
total_samples = sum(s['samples'] for s in data_summary.values() if isinstance(s.get('samples'), int))
total_size = sum(s['file_size_mb'] for s in data_summary.values() if 'file_size_mb' in s)
common_features = None

# Find common features
for tf, summary in data_summary.items():
    if 'feature_names' in summary and summary['feature_names'] != 'Unknown':
        if common_features is None:
            common_features = summary['feature_names']
        
print(f"ğŸ“Š Tá»•ng samples: {total_samples:,}")
print(f"ğŸ’¾ Tá»•ng dung lÆ°á»£ng: {total_size:.1f}MB")
print(f"ğŸ§® Features per timeframe: {data_summary['M15']['features'] if 'M15' in data_summary else 'Unknown'}")

print(f"\nğŸ¯ BÆ¯á»šC 3: PHÃ‚N TÃCH TARGETS")
print("-"*40)

# Analyze targets across timeframes
if 'M15' in data_summary and 'targets_available' in data_summary['M15']:
    sample_targets = data_summary['M15']['targets_available']
    print(f"ğŸ“‹ Available targets (from M15):")
    for target in sample_targets:
        print(f"   â€¢ {target['name']}: {target['shape']} - Positive rate: {target['positive_rate']:.3f}" if isinstance(target['positive_rate'], float) else f"   â€¢ {target['name']}: {target['shape']}")

print(f"\nğŸ”§ BÆ¯á»šC 4: ÄÃNH GIÃ KHáº¢ NÄ‚NG UNIFIED")
print("-"*40)

# Check compatibility for unified approach
compatibility_issues = []

# Check feature consistency
feature_counts = [s['features'] for s in data_summary.values() if isinstance(s.get('features'), int)]
if len(set(feature_counts)) > 1:
    compatibility_issues.append(f"Inconsistent feature counts: {set(feature_counts)}")
else:
    print("âœ… All timeframes have consistent feature count")

# Check sample counts
sample_counts = [(tf, s['samples']) for tf, s in data_summary.items() if isinstance(s.get('samples'), int)]
print(f"ğŸ“Š Sample counts by timeframe:")
for tf, count in sample_counts:
    print(f"   â€¢ {tf}: {count:,} samples")

# Check timestamp alignment potential
print(f"\nâ° Timestamp ranges:")
for tf, summary in data_summary.items():
    if 'timestamp_range' in summary and summary['timestamp_range']:
        tr = summary['timestamp_range']
        print(f"   â€¢ {tf}: {tr['start']} to {tr['end']} ({tr['duration_days']} days)")

if compatibility_issues:
    print(f"\nâš ï¸ COMPATIBILITY ISSUES:")
    for issue in compatibility_issues:
        print(f"   â€¢ {issue}")
else:
    print(f"\nâœ… NO MAJOR COMPATIBILITY ISSUES FOUND")

print(f"\nğŸ¯ BÆ¯á»šC 5: UNIFIED APPROACH STRATEGY")
print("-"*40)

print("ğŸ’¡ Äá» xuáº¥t kiáº¿n trÃºc Unified Multi-Timeframe:")
print("   1. ğŸ“Š Concat features: 67 features Ã— 7 timeframes = 469 features")
print("   2. â° Time alignment: Sá»­ dá»¥ng common timestamps")
print("   3. ğŸ¯ Single target: Chá»n má»™t target chung (e.g., y_direction_2)")
print("   4. ğŸ§  Unified model: Má»™t model nhÃ¬n toÃ n bá»™ thá»‹ trÆ°á»ng")

print(f"\nğŸ’¾ LÆ°u káº¿t quáº£ phÃ¢n tÃ­ch...")
import json
with open('multi_timeframe_analysis_results.json', 'w') as f:
    # Convert numpy types to regular types for JSON serialization
    def convert_numpy(obj):
        if isinstance(obj, np.ndarray):
            return obj.tolist()
        elif isinstance(obj, np.integer):
            return int(obj)
        elif isinstance(obj, np.floating):
            return float(obj)
        return obj
    
    # Clean data for JSON
    clean_summary = {}
    for tf, summary in data_summary.items():
        clean_summary[tf] = {}
        for key, value in summary.items():
            clean_summary[tf][key] = convert_numpy(value)
    
    json.dump(clean_summary, f, indent=2, default=str)

print("âœ… Káº¿t quáº£ Ä‘Ã£ Ä‘Æ°á»£c lÆ°u vÃ o: multi_timeframe_analysis_results.json")
print("\nğŸ PHÃ‚N TÃCH HOÃ€N Táº¤T!") 