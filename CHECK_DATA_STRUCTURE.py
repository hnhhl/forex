import pickle
import pandas as pd
import numpy as np

print("ğŸ” KIá»‚M TRA Cáº¤U TRÃšC Dá»® LIá»†U THá»°C Táº¾")
print("="*40)

# Check M15 data structure
print("\nğŸ“Š Checking M15 data structure...")
try:
    with open('training/xauusdc/data/M15_data.pkl', 'rb') as f:
        m15_data = pickle.load(f)
    
    print(f"âœ… Type: {type(m15_data)}")
    
    if isinstance(m15_data, dict):
        print(f"ğŸ“‹ Dict keys: {list(m15_data.keys())}")
        for key, value in m15_data.items():
            print(f"  ğŸ”¸ {key}: {type(value)} - {np.array(value).shape if hasattr(value, '__len__') else 'scalar'}")
    
    elif isinstance(m15_data, pd.DataFrame):
        print(f"ğŸ“Š DataFrame shape: {m15_data.shape}")
        print(f"ğŸ“‹ Columns: {list(m15_data.columns)}")
        print(f"ğŸ“ˆ Sample data:\n{m15_data.head()}")
    
    elif isinstance(m15_data, np.ndarray):
        print(f"ğŸ“Š Array shape: {m15_data.shape}")
    
    else:
        print(f"â“ Unknown type: {type(m15_data)}")
        
except Exception as e:
    print(f"âŒ Error: {e}")

# Check if we have actual trained models
print(f"\nğŸ§  KIá»‚M TRA MODELS ÄÃƒ TRAIN")
print("-"*30)

import os
model_files = []
for file in os.listdir('trained_models'):
    if file.endswith(('.h5', '.pkl')):
        model_files.append(file)
        
print(f"ğŸ“ Found {len(model_files)} model files:")
for i, file in enumerate(model_files[:10]):  # Show first 10
    size = os.path.getsize(f'trained_models/{file}') / (1024*1024)  # MB
    print(f"  {i+1}. {file} ({size:.1f}MB)")

if len(model_files) > 10:
    print(f"  ... vÃ  {len(model_files)-10} files khÃ¡c")

# Try to load one model to test
print(f"\nğŸ¯ TEST LOAD Má»˜T MODEL")
print("-"*25)

try:
    # Try neural model
    import tensorflow as tf
    model_path = 'trained_models/neural_ensemble_y_direction_2_lstm.h5'
    if os.path.exists(model_path):
        model = tf.keras.models.load_model(model_path)
        print(f"âœ… Neural model loaded successfully!")
        print(f"ğŸ“Š Input shape: {model.input_shape}")
        print(f"ğŸ“Š Output shape: {model.output_shape}")
        print(f"ğŸ§  Total params: {model.count_params():,}")
    
    # Try traditional model  
    rf_path = 'trained_models/random_forest_y_direction_2.pkl'
    if os.path.exists(rf_path):
        with open(rf_path, 'rb') as f:
            rf_model = pickle.load(f)
        print(f"âœ… Random Forest loaded successfully!")
        print(f"ğŸ“Š Type: {type(rf_model)}")
        
except Exception as e:
    print(f"âŒ Error loading models: {e}")

print(f"\nğŸ Káº¾T LUáº¬N THá»°C Táº¾:")
print("="*40)
print(f"ğŸ“ CÃ³ {len(model_files)} model files")
print(f"ğŸ’¾ Tá»•ng dung lÆ°á»£ng: {sum(os.path.getsize(f'trained_models/{f}') for f in model_files)/(1024*1024):.1f}MB")

if len(model_files) >= 15:
    print("âœ… THÃ€NH CÃ”NG: CÃ³ Ä‘á»§ models Ä‘Ã£ Ä‘Æ°á»£c train!")
else:
    print("âš ï¸ CHÆ¯A Äá»¦: Thiáº¿u má»™t sá»‘ models") 