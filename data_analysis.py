#!/usr/bin/env python3
"""
Data Analysis - Phan tich du lieu training chi tiet
"""
import pandas as pd
import os
from pathlib import Path

def analyze_training_data():
    print("="*80)
    print("PHÃ‚N TÃCH Dá»® LIá»†U TRAINING CHI TIáº¾T")
    print("="*80)
    
    total_records = 0
    total_size_mb = 0
    
    # 1. Working Free Data
    print("1. WORKING FREE DATA:")
    working_path = "data/working_free_data"
    if os.path.exists(working_path):
        for file in sorted(os.listdir(working_path)):
            if file.endswith('.csv'):
                filepath = os.path.join(working_path, file)
                size_mb = os.path.getsize(filepath) / (1024*1024)
                
                try:
                    df = pd.read_csv(filepath)
                    records = len(df)
                    date_range = f"{df.iloc[0,0]} to {df.iloc[-1,0]}" if len(df) > 0 else "No data"
                    
                    print(f"   âœ“ {file}:")
                    print(f"     - Size: {size_mb:.1f}MB")
                    print(f"     - Records: {records:,}")
                    print(f"     - Range: {date_range}")
                    
                    total_records += records
                    total_size_mb += size_mb
                    
                except Exception as e:
                    print(f"   âœ— {file}: Error reading - {e}")
    print()
    
    # 2. Maximum MT5 V2 Data
    print("2. MAXIMUM MT5 V2 DATA:")
    mt5_path = "data/maximum_mt5_v2"
    if os.path.exists(mt5_path):
        csv_files = [f for f in os.listdir(mt5_path) if f.endswith('.csv')]
        pkl_files = [f for f in os.listdir(mt5_path) if f.endswith('.pkl')]
        
        print(f"   CSV Files: {len(csv_files)}")
        print(f"   PKL Files: {len(pkl_files)}")
        
        for file in sorted(csv_files):
            filepath = os.path.join(mt5_path, file)
            size_mb = os.path.getsize(filepath) / (1024*1024)
            
            try:
                df = pd.read_csv(filepath)
                records = len(df)
                
                print(f"   âœ“ {file}: {size_mb:.1f}MB, {records:,} records")
                total_records += records
                total_size_mb += size_mb
                
            except Exception as e:
                print(f"   âœ— {file}: Error - {e}")
    print()
    
    # 3. Real Free Data
    print("3. REAL FREE DATA:")
    real_path = "data/real_free_data"
    if os.path.exists(real_path):
        csv_files = [f for f in os.listdir(real_path) if f.endswith('.csv')]
        print(f"   Files: {len(csv_files)}")
        
        for file in sorted(csv_files):
            filepath = os.path.join(real_path, file)
            size_mb = os.path.getsize(filepath) / (1024*1024)
            
            try:
                df = pd.read_csv(filepath)
                records = len(df)
                print(f"   âœ“ {file}: {size_mb:.1f}MB, {records:,} records")
                
                total_records += records
                total_size_mb += size_mb
                
            except Exception as e:
                print(f"   âœ— {file}: Error - {e}")
    print()
    
    # 4. Free Historical Data
    print("4. FREE HISTORICAL DATA:")
    hist_path = "data/free_historical_data"
    if os.path.exists(hist_path):
        csv_files = [f for f in os.listdir(hist_path) if f.endswith('.csv')]
        print(f"   Files: {len(csv_files)}")
        
        for file in sorted(csv_files):
            filepath = os.path.join(hist_path, file)
            size_mb = os.path.getsize(filepath) / (1024*1024)
            
            try:
                df = pd.read_csv(filepath)
                records = len(df)
                print(f"   âœ“ {file}: {size_mb:.1f}MB, {records:,} records")
                
                total_records += records
                total_size_mb += size_mb
                
            except Exception as e:
                print(f"   âœ— {file}: Error - {e}")
    print()
    
    # 5. Tá»•ng káº¿t
    print("="*80)
    print("Tá»”NG Káº¾T Dá»® LIá»†U:")
    print(f"   ğŸ“Š Tá»•ng records: {total_records:,}")
    print(f"   ğŸ’¾ Tá»•ng dung lÆ°á»£ng: {total_size_mb:.1f}MB")
    print(f"   ğŸ“ˆ Trung bÃ¬nh: {total_records/total_size_mb:.0f} records/MB" if total_size_mb > 0 else "")
    print()
    
    # 6. ÄÃ¡nh giÃ¡ cháº¥t lÆ°á»£ng
    print("ÄÃNH GIÃ CHáº¤T LÆ¯á»¢NG:")
    if total_records > 1000000:
        print("   ğŸš€ EXCELLENT: >1M records - Äá»§ cho deep learning")
    elif total_records > 500000:
        print("   âœ… GOOD: >500K records - Tá»‘t cho training")
    elif total_records > 100000:
        print("   âš ï¸ MODERATE: >100K records - Cáº§n thÃªm dá»¯ liá»‡u")
    else:
        print("   âŒ INSUFFICIENT: <100K records - Cáº§n nhiá»u dá»¯ liá»‡u hÆ¡n")
    
    print()
    
    # 7. Khuyáº¿n nghá»‹
    print("KHUYáº¾N NGHá»Š:")
    if total_records < 500000:
        print("   ğŸ“¥ Cáº§n download thÃªm dá»¯ liá»‡u lá»‹ch sá»­")
        print("   ğŸ”„ Sá»­ dá»¥ng multiple timeframes Ä‘á»ƒ tÄƒng data")
        print("   ğŸ¯ Focus vÃ o M1 data cho maximum records")
    else:
        print("   âœ… Dá»¯ liá»‡u Ä‘á»§ cho training cháº¥t lÆ°á»£ng cao")
        print("   ğŸš€ CÃ³ thá»ƒ báº¯t Ä‘áº§u training ngay")
    
    print("="*80)

if __name__ == "__main__":
    analyze_training_data() 